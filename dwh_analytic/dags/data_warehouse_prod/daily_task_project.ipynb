{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/duynguyenngoc/Desktop/project/analytic/dwh_analytic/dags/data_warehouse_prod\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/duynguyenngoc/Desktop/project/analytic/dwh_analytic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "import pendulum\n",
    "from dags.data_warehouse_prod.functions import function as func\n",
    "from dags.data_warehouse_prod.functions.report import initial_report\n",
    "from dags.data_warehouse_prod.functions.db_connect import EngineConnect as DatabaseConnect\n",
    "from dags.data_warehouse_prod.settings import config\n",
    "from dags.data_warehouse_prod.schema.loading_data import LoadingData\n",
    "from dags.data_warehouse_prod.schema.backup_data_with_report import BackupData\n",
    "from dags.data_warehouse_prod.schema.fact_document import FactDocumentModel\n",
    "from dags.data_warehouse_prod.schema.fact_performance import FactPerformanceModel\n",
    "from dags.data_warehouse_prod.schema.fact_data_extraction import FactDataExtractionModel\n",
    "from dags.data_warehouse_prod.schema.dim_project_variable import DimProjectVariableModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connect = DatabaseConnect(uri = config.DWH_SQLALCHEMY_URI)\n",
    "project_variable = DimProjectVariableModel(project_id = '5e9e7ec598d753001b7efe6b')\n",
    "project_variable.init_schema(db_connect)\n",
    "project_variable.init_data(db_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadingDataModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *kwagrs,\n",
    "        \n",
    "    )\n",
    "class ProjectExecutor(LoadingDataModel, BackupDataModel, CleanDataModel, ReportDataModel ,DimProjectVariableModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *kwargs,\n",
    "        environment: str,\n",
    "        project_id: str,\n",
    "        environment: str,\n",
    "        uri: str,\n",
    "        database_name: str = 'elrond',\n",
    "        db: DatabaseConnect\n",
    "    ):\n",
    "        self.db = db\n",
    "        self.environment = environment\n",
    "        self.project_id = project_id\n",
    "        self.database_name  = database_name\n",
    "        \n",
    "\n",
    "    \n",
    "    def run_backup_docs(self):\n",
    "        pass\n",
    "    \n",
    "    def run_backup_trans(self):\n",
    "        pass\n",
    "    \n",
    "    def run_backup_performance(self):\n",
    "        pass\n",
    "    \n",
    "    def run_backup_field(self):\n",
    "        pass\n",
    "    \n",
    "    def run_report(self):\n",
    "        pass\n",
    "    \n",
    "    def run_dim_field(self):\n",
    "        pass\n",
    "    \n",
    "    def run_fact_document(self):\n",
    "        pass\n",
    "    \n",
    "    def run_fact_perfromance(self):\n",
    "        pass\n",
    "    \n",
    "    def run_fact_data_extraction(self):    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': '(sqlite3.InterfaceError) Error binding parameter 4 - probably '\n",
      "                'unsupported type.\\n'\n",
      "                '[SQL: INSERT INTO fact_document (document_key, '\n",
      "                'ori_document_id, project_id, document_id, doc_set_id, '\n",
      "                'import_time_key, import_date_key, export_time_key, '\n",
      "                'export_date_key, import_timestamp, export_timestamp, '\n",
      "                'remark_code, remark_description) VALUES (?, ?, ?, ?, ?, ?, ?, '\n",
      "                '?, ?, ?, ?, ?, ?)]\\n'\n",
      "                \"[parameters: ((1, '5ffbaffc489b01001ed5a29f', \"\n",
      "                \"'5e9e7ec598d753001b7efe6b', '5ff2df89474eb70010c1a5aa', \"\n",
      "                \"('5ff2df89474eb70010c1a4de',), 162737, 20210104, 85508, \"\n",
      "                \"20210111, '2021-01-04 16:27:37.617000', '2021-01-11 \"\n",
      "                \"08:55:08.149000', None, None), (2, \"\n",
      "                \"'5ffbaffc489b01001ed5a2a0', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5ab', ('5ff2df89474eb70010c1a4df',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.209000', None, None), \"\n",
      "                \"(3, '5ffbaffc489b01001ed5a2a1', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5ac', ('5ff2df89474eb70010c1a4e0',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.280000', None, None), \"\n",
      "                \"(4, '5ffbaffc489b01001ed5a2a2', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5ad', ('5ff2df89474eb70010c1a4e1',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.302000', None, None), \"\n",
      "                \"(5, '5ffbaffc489b01001ed5a2a3', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5ae', ('5ff2df89474eb70010c1a4e2',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.391000', None, None), \"\n",
      "                \"(6, '5ffbaffc489b01001ed5a2a4', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5af', ('5ff2df89474eb70010c1a4e3',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.480000', None, None), \"\n",
      "                \"(7, '5ffbaffc489b01001ed5a2a5', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5b0', ('5ff2df89474eb70010c1a4e4',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.574000', None, None), \"\n",
      "                \"(8, '5ffbaffc489b01001ed5a2a6', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff2df89474eb70010c1a5b1', ('5ff2df89474eb70010c1a4e5',), \"\n",
      "                \"162737, 20210104, 85508, 20210111, '2021-01-04 \"\n",
      "                \"16:27:37.617000', '2021-01-11 08:55:08.598000', None, None)  \"\n",
      "                '... displaying 10 of 2145 total bound parameter sets ...  '\n",
      "                \"(2144, '5ffc33b61b3ae8001e142f57', \"\n",
      "                \"'5e9e7ec598d753001b7efe6b', '5ff5a00e474eb70010c28785', \"\n",
      "                \"('5ff5a00e474eb70010c2870b',), 183334, 20210106, 181710, \"\n",
      "                \"20210111, '2021-01-06 18:33:34.863000', '2021-01-11 \"\n",
      "                \"18:17:10.678000', None, None), (2145, \"\n",
      "                \"'5ffc33b61b3ae8001e142f58', '5e9e7ec598d753001b7efe6b', \"\n",
      "                \"'5ff5a00f474eb70010c28847', ('5ff5a00e474eb70010c28789',), \"\n",
      "                \"183335, 20210106, 181710, 20210111, '2021-01-06 \"\n",
      "                \"18:33:35.000000', '2021-01-11 18:17:10.693000', None, \"\n",
      "                'None))]\\n'\n",
      "                '(Background on this error at: http://sqlalche.me/e/13/rvf5)',\n",
      " 'executor_date_key': 2021117,\n",
      " 'executor_date_timestamp': datetime.datetime(2021, 1, 17, 1, 9, 13, 373131, tzinfo=tzfile('/usr/share/zoneinfo/Asia/Ho_Chi_Minh')),\n",
      " 'executor_time_key': 1913,\n",
      " 'job_name': 'fact_document',\n",
      " 'project_id': '5e9e7ec598d753001b7efe6b',\n",
      " 'schedule_date_key': 20200113,\n",
      " 'schedule_time_key': 50000,\n",
      " 'status_code': 'FAILED',\n",
      " 'total_time_run_second': 2.6737756729125977}\n"
     ]
    }
   ],
   "source": [
    "class GdaExecutor(LoadingData, BackupData):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *kwargs,\n",
    "        environment: str,\n",
    "        uri: str,\n",
    "        database_name: str,\n",
    "        docs_collection_name: str, \n",
    "        trans_collection_name: str,\n",
    "        performance_collection_name: str,\n",
    "        db: DatabaseConnect\n",
    "    ):\n",
    "        self.environment = environment\n",
    "        self.uri = uri\n",
    "        self.database_name = database_name\n",
    "        self.docs_collection_name = docs_collection_name\n",
    "        self.trans_collection_name = trans_collection_name\n",
    "        self.performance_collection_name = performance_collection_name\n",
    "        self.db = db\n",
    "        self.maxSevSelDelay = 20000\n",
    "        self.start = config.start\n",
    "        self.query = config.GDA_QUERY\n",
    "        self.performance_query = config.GDA_PERFORMANCE_QUERY\n",
    "        self.project_id = config.GDA_PROJECT_ID\n",
    "        self.project_name = config.GDA_PROJECT_NAME\n",
    "        self.backup_dir = config.BACKUP_DIR\n",
    "        self.project_backup_dir = config.GDA_BACKUP_DIR\n",
    "        self.project_docs_dir = config.GDA_DOCS_DIR\n",
    "        self.project_trans_dir = config.GDA_TRANS_DIR\n",
    "        self.project_field_dir = config.GDA_FIELD_DIR\n",
    "        self.project_performance_dir = config.GDA_PERFORMANCE_DIR\n",
    "        self.backup_file_type = config.BACKUP_FILE_TYPE\n",
    "        self.schema = config.DWH_ANALYTIC_SCHEMA\n",
    "        self.fact_document_table = config.DWH_FACT_DOCUMENT_TABLE\n",
    "        self.fact_performance_table = config.DWH_FACT_PERFORMANCE_TABLE\n",
    "        self.fact_data_extraction_table = config.DWH_FACT_DATA_EXTRACTION_TABLE\n",
    "        self.fact_report_table = config.DWH_FACT_REPORT_ETL_TABLE\n",
    "        self.schedule_type = 'daily'\n",
    "        self.schedule_date_key = 20200113\n",
    "        self.schedule_time_key = 50000\n",
    "        self.reports = []\n",
    "        self.document_key_checks = []\n",
    "        self.performance_key_checks = []\n",
    "    \n",
    "    def run_clean(self):\n",
    "        report = self.clean()\n",
    "        self.reports.append(report)\n",
    "        return report\n",
    "    \n",
    "    def run_backup_trans(self):\n",
    "        report = self.backup_trans()\n",
    "        self.reports.append(report)\n",
    "        return report\n",
    "\n",
    "    def run_backup_docs(self):\n",
    "        report = self.backup_docs()\n",
    "        self.reports.append(report)\n",
    "        return report\n",
    "        \n",
    "            \n",
    "    def run_backup_performance(self):\n",
    "        report = self.backup_performance()\n",
    "        self.reports.append(report)\n",
    "        return report\n",
    "    \n",
    "    \n",
    "    def fact_document(self):\n",
    "        report = initial_report('fact_document', self.project_id, self.schedule_type, self.schedule_date_key, self.schedule_time_key)\n",
    "        start_run = time.time()\n",
    "        try:\n",
    "            datas = []\n",
    "            data_docs, data_trans = self.get_docs_and_trans()\n",
    "            list_created = [{'doc_id': func.bson_object_to_string(data['_id']), 'created_date': data['created_date']} for data in data_docs]\n",
    "            _id = self.db.get_max_id_table(schema = self.schema, table = self.fact_document_table, col = 'document_key')\n",
    "            if _id == None:\n",
    "                _id = 1\n",
    "            else:\n",
    "                _id+=1\n",
    "            _id =1\n",
    "            for data in data_trans:\n",
    "                if len(data['records']) == 0:\n",
    "                    continue\n",
    "                created_date_utc_7  = func.created_date_of_docs_by_id(func.bson_object_to_string(data['doc_id']), list_created) + datetime.timedelta(hours = 7)\n",
    "                last_modified_utc_7 = data['last_modified'] + datetime.timedelta(hours = 7)\n",
    "                import_date_key_utc_7, import_time_key_utc_7 = func.handle_date_to_date_and_time_id(created_date_utc_7)\n",
    "                export_date_key_utc_7, export_time_key_utc_7 = func.handle_date_to_date_and_time_id(last_modified_utc_7)\n",
    "                document_id = func.bson_object_to_string(data['doc_id'])\n",
    "                doc_set_id = func.bson_object_to_string(data['doc_set_id']),\n",
    "                _obj = FactDocumentModel(\n",
    "                    document_key = _id,\n",
    "                    ori_document_id = func.bson_object_to_string(data['_id']),\n",
    "                    project_id = self.project_id,\n",
    "                    document_id = document_id,\n",
    "                    doc_set_id =  doc_set_id,\n",
    "                    remark_code = None,\n",
    "                    remark_description = None,\n",
    "                    import_date_key = import_date_key_utc_7,\n",
    "                    import_time_key = import_time_key_utc_7,\n",
    "                    export_date_key = export_date_key_utc_7,\n",
    "                    export_time_key = export_time_key_utc_7,\n",
    "                    import_timestamp = created_date_utc_7,\n",
    "                    export_timestamp = last_modified_utc_7,\n",
    "                )\n",
    "                self.document_key_checks.append({'document_key': _id, 'document_id': document_id, 'doc_set_id': doc_set_id})\n",
    "                datas.append(_obj)\n",
    "                _id+=1\n",
    "            self.db.create([item.__dict__ for item in datas], self.schema, self.fact_document_table)\n",
    "            df = pd.json_normalize([item.__dict__ for item in datas])\n",
    "            report.status_code = 'PASSED'\n",
    "        except Exception as e:\n",
    "            report.status_code = 'FAILED'\n",
    "            report.description = str(e)\n",
    "        finally:\n",
    "            report.total_time_run_second = time.time()-start_run\n",
    "            self.reports.append(report)\n",
    "            return report\n",
    "\n",
    "db_connect = DatabaseConnect(uri = config.DWH_SQLALCHEMY_URI)\n",
    "executor = GdaExecutor(\n",
    "    environment=config.ENVIRONMENT,\n",
    "    uri=config.ELROND_URI,\n",
    "    database_name=config.ELROND_DATABASE,\n",
    "    docs_collection_name= config.GDA_DOCS_COLLECTION, \n",
    "    trans_collection_name= config.GDA_TRANS_COLLECTION,\n",
    "    performance_collection_name = config.GDA_PERFORMANCE_COLLECTION,\n",
    "    db = db_connect\n",
    ")\n",
    "\n",
    "# executor.run_clean()\n",
    "# executor.run_backup_docs()\n",
    "# executor.run_backup_performance()\n",
    "# executor.run_backup_trans()\n",
    "re = executor.fact_document()\n",
    "pprint(re.__dict__)\n",
    "# executor.fact_performance()\n",
    "# executor.fact_data_extract() \n",
    "# executor.report_upload()\n",
    "# executor.show_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': '(sqlite3.OperationalError) no such table: '\n",
      "                'dwh_development_analytic.fact_document\\n'\n",
      "                '[SQL: select max(document_key) from '\n",
      "                'dwh_development_analytic.\"fact_document\";]\\n'\n",
      "                '(Background on this error at: http://sqlalche.me/e/13/e3q8)',\n",
      " 'executor_date_key': 2021117,\n",
      " 'executor_date_timestamp': datetime.datetime(2021, 1, 17, 1, 5, 45, 790863, tzinfo=tzfile('/usr/share/zoneinfo/Asia/Ho_Chi_Minh')),\n",
      " 'executor_time_key': 1545,\n",
      " 'job_name': 'fact_document',\n",
      " 'project_id': '5e9e7ec598d753001b7efe6b',\n",
      " 'schedule_date_key': 20200113,\n",
      " 'schedule_time_key': 50000,\n",
      " 'status_code': 'FAILED',\n",
      " 'total_time_run_second': 2.618730068206787}\n"
     ]
    }
   ],
   "source": [
    "db_connect = DatabaseConnect(uri = config.DWH_SQLALCHEMY_URI)\n",
    "executor = GdaExecutor(\n",
    "    environment=config.ENVIRONMENT,\n",
    "    uri=config.ELROND_URI,\n",
    "    database_name=config.ELROND_DATABASE,\n",
    "    docs_collection_name= config.GDA_DOCS_COLLECTION, \n",
    "    trans_collection_name= config.GDA_TRANS_COLLECTION,\n",
    "    performance_collection_name = config.GDA_PERFORMANCE_COLLECTION,\n",
    "    db = db_connect\n",
    ")\n",
    "\n",
    "# executor.run_clean()\n",
    "# executor.run_backup_docs()\n",
    "# executor.run_backup_performance()\n",
    "# executor.run_backup_trans()\n",
    "re = executor.fact_document()\n",
    "pprint(re.__dict__)\n",
    "# executor.fact_performance()\n",
    "# executor.fact_data_extract() \n",
    "# executor.report_upload()\n",
    "# executor.show_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    def fact_performance(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "   def get_document_key_by_document_id(self, document_id: str):\n",
    "        document_key = None\n",
    "        for item in self.document_key_checks:\n",
    "            if item['document_id'] == document_id:\n",
    "                document_key = item['document_key']\n",
    "                break\n",
    "        return document_key\n",
    "    \n",
    "    def fact_performance(self):\n",
    "        report = initial_report('fact_performance', self.project_id, self.schedule_type, self.schedule_date_key, self.schedule_time_key)\n",
    "        start_run = time.time()\n",
    "        try:\n",
    "            datas = []\n",
    "            data_performance = self.get_performance()\n",
    "            _id = self.db.get_max_id_table(schema = self.schema, table = self.fact_performance_table, col ='performance_key')\n",
    "            if _id == None:\n",
    "                _id = 1\n",
    "            else:\n",
    "                _id+=1\n",
    "            for performance in data_performance:\n",
    "                captured_date_timestamp_utc_7 = performance['time'] + datetime.timedelta(hours = 7)\n",
    "                document_key = self.get_document_key_by_document_id(performance['doc_id'])\n",
    "                obj_ = FactPerformanceModel(\n",
    "                        performance_key = _id,\n",
    "                        ori_performance_id = func.bson_object_to_string(performance['_id']),\n",
    "                        document_key = document_key,\n",
    "                        project_id = self.project_id,  \n",
    "                        group_id = performance['group_id'],  \n",
    "                        document_id = performance['doc_id'],  \n",
    "                        reworked = func.int_to_bool(performance['rework_count']),  \n",
    "                        work_type_key = func.get_working_type_id_by_name(performance['work_type']),  \n",
    "                        process_key = func.get_process_key_performance_gda(performance['type'], performance['task_def_key']),  \n",
    "                        number_of_record = performance['records'],\n",
    "                        number_of_item = performance['items'],  \n",
    "                        number_of_field = performance['fields'],\n",
    "                        number_of_character = performance['chars'],  \n",
    "                        user_name = performance['username'], \n",
    "                        ip = performance['ip'], \n",
    "                        captured_date_timestamp = captured_date_timestamp_utc_7,  \n",
    "                        captured_date_key = func.time_to_date_key(captured_date_timestamp_utc_7),  \n",
    "                        captured_time_key = func.time_to_time_key(captured_date_timestamp_utc_7),  \n",
    "                        total_time_second = performance['total_time']    \n",
    "                )\n",
    "                datas.append(obj_)\n",
    "                self.performance_key_checks.append({'performance_key': _id, 'user_name': performance['username'], \n",
    "                                                    'document_key': document_key, 'module_type': performance['type'], \n",
    "                                                    'task_def_key': performance['task_def_key']})\n",
    "                _id+=1\n",
    "            self.db.create([item.__dict__ for item in datas], self.schema, self.fact_performance_table)\n",
    "            report.status_code = 'PASSED'\n",
    "        except Exception as e:\n",
    "            report.status_code = 'FAILED'\n",
    "            report.description = str(e)\n",
    "            pprint(e)\n",
    "        finally:\n",
    "            report.total_time_run_second = time.time()-start_run\n",
    "            self.reports.append(report)\n",
    "            return report\n",
    "        \n",
    "    def get_performance_key(self, document_key: str, user_name: str, module_type: str, task_def_key: str):\n",
    "        performance_key = None\n",
    "        for item in self.performance_key_checks:\n",
    "            if item['user_name'] == user_name and item['module_type'] == module_type and item['document_key'] == document_key and item['task_def_key'] == task_def_key:\n",
    "                performance_key = item['performance_key']\n",
    "                break\n",
    "        return performance_key\n",
    "                                                   \n",
    "    def fact_data_extract(self):\n",
    "        report = initial_report('fact_data_extraction', self.project_id, self.schedule_type, self.schedule_date_key, self.schedule_time_key)\n",
    "        start_run = time.time()\n",
    "        try:\n",
    "            data_docs, data_trans = self.get_docs_and_trans()\n",
    "            col_ignores = ['ImagePath']\n",
    "            results = []                \n",
    "            for data in data_docs:\n",
    "                records = data['records']\n",
    "                document_id = func.bson_object_to_string(data['_id'])          \n",
    "                document_key = self.get_document_key_by_document_id(document_id)\n",
    "                doc_set_id = func.bson_object_to_string(data['doc_set_id'])\n",
    "                for record in records:\n",
    "                    for key, value in record.items():\n",
    "                        if key == 'keyed_data':\n",
    "                            for keyed_data in value:\n",
    "                                source = keyed_data['source']\n",
    "                                task_def_key = keyed_data['task_def_key']\n",
    "#                                 task_id = keyed_data['task_id']\n",
    "#                                 section = keyed_data['section']\n",
    "#                                 reason = keyed_data['reason']\n",
    "                                data_needed = keyed_data['data'][0].items()\n",
    "                                last_modified_utc_7 = keyed_data['createdtime'] + datetime.timedelta(hours = 7)\n",
    "                                user_name = keyed_data['keyer']\n",
    "                                performance_key = None\n",
    "                                if source != 'queue_transform' and task_def_key.startswith('Type'):\n",
    "                                    process_key = 3 # human input keyed_data kpi\n",
    "                                    performance_key = self.get_performance_key(document_key, user_name, 'keying', task_def_key) \n",
    "                                if source != 'queue_transform' and task_def_key == 'Verify_Hold_Type':\n",
    "                                    process_key = 12 # human check bad_image keyed_data not kpi                               \n",
    "                                elif source == 'queue_transform' and task_def_key.startswith('Type'):\n",
    "                                    process_key = 4 # 'machine save input keyed_data'\n",
    "                                elif source != 'queue_transform' and task_def_key.startswith('Proof'):\n",
    "                                    process_key = 5 # human qc input keyed_data' kpi\n",
    "                                    performance_key = self.get_performance_key(document_key, user_name, 'keying', task_def_key)                                  \n",
    "                                elif source == 'queue_transform' and task_def_key.startswith('Proof'):\n",
    "                                    process_key = 6 # 'machine save qc keyed_data'\n",
    "                                for field_name, field_value_dict in data_needed:\n",
    "                                    if field_name in col_ignores:\n",
    "                                        continue\n",
    "                                    _obj = FactDataExtractionModel(\n",
    "                                        document_key = document_key,\n",
    "                                        performance_key = performance_key,\n",
    "                                        ori_document_id = document_id,\n",
    "                                        project_id = self.project_id,\n",
    "                                        document_id = document_id,\n",
    "                                        doc_set_id =  doc_set_id,\n",
    "                                        last_modified_date_key = func.time_to_date_key(last_modified_utc_7),\n",
    "                                        last_modified_time_key = func.time_to_time_key(last_modified_utc_7),\n",
    "                                        last_modified_timestamp = last_modified_utc_7,\n",
    "                                        user_name = user_name,\n",
    "                                        process_key = process_key,\n",
    "                                        field_name = field_name,\n",
    "                                        field_value = field_value_dict['text']\n",
    "                                    )\n",
    "                                    results.append(_obj)\n",
    "\n",
    "                        elif key == 'final_data':\n",
    "                            final_data = value[0]\n",
    "                            data_needed = final_data['data'][0].items()\n",
    "                            last_modified_utc_7 = final_data['createdtime'] + datetime.timedelta(hours = 7)\n",
    "                            user_name = final_data['keyer']\n",
    "                            process_key = 10\n",
    "                            for field_name, field_value_dict in data_needed:\n",
    "                                if field_name in col_ignores:\n",
    "                                    continue\n",
    "                                _obj = FactDataExtractionModel(\n",
    "                                    document_key = document_key,\n",
    "                                    performance_key = None,\n",
    "                                    ori_document_id = document_id,\n",
    "                                    project_id = self.project_id,\n",
    "                                    document_id = document_id,\n",
    "                                    doc_set_id =  doc_set_id,\n",
    "                                    last_modified_date_key = func.time_to_date_key(last_modified_utc_7),\n",
    "                                    last_modified_time_key = func.time_to_time_key(last_modified_utc_7),\n",
    "                                    last_modified_timestamp = last_modified_utc_7,\n",
    "                                    user_name = user_name,\n",
    "                                    process_key = process_key,\n",
    "                                    field_name = field_name,\n",
    "                                    field_value = field_value_dict['text']\n",
    "                                )\n",
    "                                results.append(_obj)\n",
    "\n",
    "                        elif key == 'qc_ed_data':\n",
    "                            qc_ed_data = value[0][0]\n",
    "                            if 'qc_fields_err' not in qc_ed_data.keys():\n",
    "                                continue\n",
    "                            qc_ed_data_err = qc_ed_data['qc_fields_err']\n",
    "                            data_needed = qc_ed_data_err[0].items()\n",
    "                            last_modified_utc_7 = qc_ed_data['createdtime'] + datetime.timedelta(hours = 7)\n",
    "                            user_name = qc_ed_data['keyer']\n",
    "                            process_key = 8\n",
    "                            performance_key = None\n",
    "                            performance_key = self.get_performance_key(document_key, user_name, 'qc', task_def_key) \n",
    "                            for field_name, field_value_dict in data_needed:\n",
    "                                if field_name in col_ignores:\n",
    "                                    continue\n",
    "                                _obj = FactDataExtractionModel(\n",
    "                                    document_key = document_key,\n",
    "                                    performance_key = performance_key,\n",
    "                                    ori_document_id = document_id,\n",
    "                                    project_id = self.project_id,\n",
    "                                    document_id = document_id,\n",
    "                                    doc_set_id =  doc_set_id,\n",
    "                                    last_modified_date_key = func.time_to_date_key(last_modified_utc_7),\n",
    "                                    last_modified_time_key = func.time_to_time_key(last_modified_utc_7),\n",
    "                                    last_modified_timestamp = last_modified_utc_7,\n",
    "                                    user_name = user_name,\n",
    "                                    process_key = process_key,\n",
    "                                    field_name = field_name,\n",
    "                                    field_value = field_value_dict['text']\n",
    "                                )\n",
    "                                results.append(_obj)\n",
    "\n",
    "                        elif key == 'apr_ed_data':\n",
    "                            report.description = 'Not handle aprove qc data because not have sample data'\n",
    "#             for data in data_trans:\n",
    "                \n",
    "\n",
    "            self.db.create([item.__dict__ for item in results], self.schema, self.fact_data_extraction_table)\n",
    "            report.status_code = 'PASSED'\n",
    "        except Exception as e:\n",
    "            report.status_code = 'FAILED'\n",
    "            report.description = str(e)\n",
    "        finally:\n",
    "            report.total_time_run_second = time.time()-start_run\n",
    "            self.reports.append(report)\n",
    "            return report\n",
    "\n",
    "    def report_upload(self):\n",
    "        self.db.create([item.__dict__ for item in self.reports], self.schema, self.fact_report_table)\n",
    "    \n",
    "    def show_report(self):\n",
    "        for report in self.reports:\n",
    "            pprint(report.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
