{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pickle\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "import pendulum\n",
    "\n",
    "import config\n",
    "import function as func\n",
    "\n",
    "from schema.fact_document import FactDocumentModel\n",
    "from schema.fact_performance import FactPerformanceModel\n",
    "from schema.fact_data_extraction import FactDataExtractionModel\n",
    "from db_connect import EngineConnect as DatabaseConnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EclaimsExecutor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *kwargs,\n",
    "        environment: str,\n",
    "        uri: str,\n",
    "        database_name: str,\n",
    "        docs_collection_name: str, \n",
    "        trans_collection_name: str,\n",
    "        performance_collection_name: str,\n",
    "        db: DatabaseConnect\n",
    "    ):\n",
    "        self.environment = environment\n",
    "        self.uri = uri\n",
    "        self.database_name = database_name\n",
    "        self.docs_collection_name = docs_collection_name\n",
    "        self.trans_collection_name = trans_collection_name\n",
    "        self.performance_collection_name = performance_collection_name\n",
    "        self.db = db\n",
    "        self.start_run = time.time()\n",
    "        self.maxSevSelDelay = 20000\n",
    "        self.start = config.start\n",
    "        self.query = config.ECLAIMS_QUERY\n",
    "        self.performance_query = config.ECLAIMS_PERFORMANCE_QUERY\n",
    "        self.project_id = config.ECLAIMS_PROJECT_ID\n",
    "        self.project_name = config.ECLAIMS_PROJECT_NAME\n",
    "        self.backup_dir = config.BACKUP_DIR\n",
    "        self.project_backup_dir = config.ECLAIMS_BACKUP_DIR\n",
    "        self.project_docs_dir = config.ECLAIMS_DOCS_DIR\n",
    "        self.project_trans_dir = config.ECLAIMS_TRANS_DIR\n",
    "        self.project_performance_dir = config.ECLAIMS_PERFORMANCE_DIR\n",
    "        self.backup_file_type = config.BACKUP_FILE_TYPE\n",
    "        self.schema = config.DWH_ANALYTIC_SCHEMA\n",
    "        self.fact_document_table = config.DWH_FACT_DOCUMENT_TABLE\n",
    "        self.fact_performancec_table = config.DWH_FACT_PERFORMANCE_TABLE\n",
    "        self.fact_data_extraction = config.DWH_FACT_DATA_EXTRACTION_TABLE\n",
    "        \n",
    "    def get_docs_and_trans(self):\n",
    "        if self.environment == 'development':\n",
    "            obj_docs = pickle.load(open('./backup/docs/' + self.project_id + '.pickle', 'rb'))\n",
    "            obj_trans = pickle.load(open('./backup/trans/' + self.project_id + '.pickle', 'rb'))\n",
    "        else: \n",
    "            obj_docs = pickle.load(open(self.backup_dir + self.project_backup_dir + self.project_docs_dir + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'rb'))\n",
    "            obj_trans = pickle.load(open(self.backup_dir + self.project_backup_dir + self.project_trans_dir + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'rb'))\n",
    "        data_docs = [item for item in obj_docs]\n",
    "        data_trans = [item for item in obj_trans]\n",
    "        return data_docs, data_trans\n",
    "\n",
    "    def get_performance(self):\n",
    "        if self.environment == 'development':\n",
    "            obj_performance = pickle.load(open('./backup/performance/' + self.project_id + '.pickle', 'rb'))\n",
    "        else:\n",
    "            obj_performance = pickle.load(open(self.backup_dir + self.project_backup_dir + self.project_performance_dir + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'rb'))\n",
    "        data_performance = [item for item in obj_performance]\n",
    "        return data_performance\n",
    "        \n",
    "    def fact_document(self):\n",
    "        datas = []\n",
    "        data_docs, data_trans = self.get_docs_and_trans()\n",
    "        list_created = [data['created_date'] for data in data_docs]\n",
    "        meta_datas = [data['project_meta_data'] for data in data_docs]\n",
    "        for data in data_trans:\n",
    "            if len(data['records']) == 0:\n",
    "                continue\n",
    "            records = data['records'][0]\n",
    "            created_date_utc_7 = func.check_index_data_docs(meta_datas, list_created, records['requestId'], records['caseId'], records['caseNumber']) \\\n",
    "                + datetime.timedelta(hours = 7)\n",
    "            last_modified_utc_7 = data['last_modified'] + datetime.timedelta(hours = 7)\n",
    "            import_date_key_utc_7, import_time_key_utc_7 = func.handle_date_to_date_and_time_id(created_date_utc_7)\n",
    "            export_date_key_utc_7, export_time_key_utc_7 = func.handle_date_to_date_and_time_id(last_modified_utc_7)\n",
    "            remark_code = None\n",
    "            if records['remarkCode'] != None and records['remarkCode'] != '':\n",
    "                remark_code = records['remarkCode']\n",
    "            _obj = FactDocumentModel(\n",
    "                project_id = self.project_id,\n",
    "                document_id = func.bson_object_to_string(data['doc_id']),\n",
    "                doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "                remark_code = remark_code,\n",
    "                remark_description = None,\n",
    "                import_date_key = import_date_key_utc_7,\n",
    "                import_time_key = import_time_key_utc_7,\n",
    "                export_date_key = export_date_key_utc_7,\n",
    "                export_time_key = export_time_key_utc_7,\n",
    "                import_timestamp = created_date_utc_7,\n",
    "                export_timestamp = last_modified_utc_7,\n",
    "            )\n",
    "            datas.append(_obj)\n",
    "        if datas != []:\n",
    "            print(datas[0].__dict__)\n",
    "        self.db.create([item.__dict__ for item in datas], self.schema, self.fact_document_table)\n",
    "                            \n",
    "    def fact_performance(self):\n",
    "        datas = []\n",
    "        data_performance = self.get_performance()\n",
    "        for performance in data_performance:\n",
    "            captured_date_timestamp = datetime.datetime.strptime(performance['captured_date'], '%d/%m/%Y')\n",
    "            obj_ = FactPerformanceModel(\n",
    "                    ori_id = func.bson_object_to_string(performance['_id']),  \n",
    "                    project_id = self.project_id,  \n",
    "                    group_id = performance['group_id'],  \n",
    "                    document_id = performance['documentId'],  \n",
    "                    reworked = performance['has_rework'],  \n",
    "                    work_type_id = func.get_working_type_id_by_name(performance['work_type']),  \n",
    "                    process_key = func.get_process_id_performance(performance['type']),  \n",
    "                    number_of_record = performance['records'],  \n",
    "                    user_name = performance['username'], \n",
    "                    ip = None, \n",
    "                    captured_date_timestamp = captured_date_timestamp,  \n",
    "                    captured_date_key = func.time_to_date_key(captured_date_timestamp),  \n",
    "                    captured_time_key = 0,  \n",
    "                    total_time_second = performance['total_time']/100     \n",
    "            )\n",
    "            datas.append(obj_)\n",
    "        if datas != []:\n",
    "            print(datas[0].__dict__)\n",
    "        self.db.create([item.__dict__ for item in datas], self.schema, self.fact_performancec_table)\n",
    "    \n",
    "    def check_connect(self):\n",
    "        if self.environment == 'development':\n",
    "            (status, content, time_run) = (True, \"good!\",  time.time()- self.start_run)\n",
    "        else:\n",
    "            client = MongoClient(self.uri, serverSelectionTimeoutMS= self.maxSevSelDelay)\n",
    "            client.server_info()\n",
    "            client.close()\n",
    "            (status, content, time_run) = (True, \"good!\",  time.time()-self.start_run)\n",
    "        print('check_connect done!')\n",
    "        return {\"status\": status, \"content\": content, \"time\": time_run}\n",
    "    \n",
    "    def backup_performance(self):\n",
    "        if self.environment == 'development':\n",
    "            objects = pickle.load(open('./backup/performance/' + self.project_id + '.pickle', 'rb'))\n",
    "            data_objects = [item for item in objects]\n",
    "            handle = open('./backup_test/performance_' + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'wb')\n",
    "            pickle.dump(data_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            handle.close()\n",
    "        else:\n",
    "            client = MongoClient(self.uri)\n",
    "            data_query = client[self.database_name][self.performance_collection_name].find(self.query)\n",
    "            data_objects = [item for item in data_query]\n",
    "            client.close()\n",
    "            handle = open(self.backup_dir + self.project_backup_dir + self.project_performance_dir + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'wb')\n",
    "            pickle.dump(data_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            handle.close()\n",
    "        print('backup_performance done!')\n",
    "        \n",
    "    def backup_docs(self):\n",
    "        if self.environment == 'development':\n",
    "            objects = pickle.load(open('./backup/docs/' + self.project_id + '.pickle', 'rb'))\n",
    "            data_objects = [item for item in objects]\n",
    "            handle = open('./backup_test/docs_' + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'wb')\n",
    "            pickle.dump(data_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            handle.close()\n",
    "        else:\n",
    "            client = MongoClient(self.uri)\n",
    "            data_query = client[self.database_name][self.docs_collection_name].find(self.query)\n",
    "            data_objects = [item for item in data_query]\n",
    "            client.close()\n",
    "            handle = open(self.backup_dir + self.project_backup_dir + self.project_docs_dir + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'wb')\n",
    "            pickle.dump(data_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            handle.close()\n",
    "        print('backup_docs done!')\n",
    "    \n",
    "    def backup_trans(self):\n",
    "        if self.environment == 'development':\n",
    "            objects = pickle.load(open('./backup/trans/' + self.project_id + '.pickle', 'rb'))\n",
    "            data_objects = [item for item in objects]\n",
    "            handle = open('./backup_test/tran_' + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type, 'wb')\n",
    "            pickle.dump(data_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            handle.close()\n",
    "        else:\n",
    "            client = MongoClient(self.uri)\n",
    "            data_query = client[self.database_name][self.trans_collection_name].find(self.query)\n",
    "            data_objects = [item for item in data_query]\n",
    "            client.close()\n",
    "            handle = open(self.backup_dir + self.project_backup_dir + self.project_trans_dir + str(self.start.strftime(\"%Y-%m-%d\")) + self.backup_file_type , 'wb')\n",
    "            pickle.dump(data_objects, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            handle.close()\n",
    "        print('backup_trans done!')\n",
    "    \n",
    "    def report(self):\n",
    "        print('report done!')\n",
    "    \n",
    "    def clean(self): \n",
    "        if self.environment == 'development' or self.environment == 'production':\n",
    "            now = self.start - timedelta(days=1)\n",
    "            file_name = str(now.strftime(\"%Y-%m-%d\"))\n",
    "            docs_file_path = self.backup_dir + self.project_backup_dir + self.project_docs_dir + file_name + self.backup_file_type\n",
    "            trans_file_path = self.backup_dir + self.project_backup_dir + self.project_trans_dir + file_name + self.backup_file_type\n",
    "            performance_file_path = self.backup_dir + self.project_backup_dir + self.project_performance_dir + file_name + self.backup_file_type\n",
    "            if os.path.exists(performance_file_path):\n",
    "                os.remove(performance_file_path)\n",
    "            else:\n",
    "                print(\"The performance_file_path does not exist\")\n",
    "            if os.path.exists(docs_file_path):\n",
    "                os.remove(docs_file_path)\n",
    "            else:\n",
    "                print(\"The docs_file_path does not exist\")\n",
    "            if os.path.exists(trans_file_path):\n",
    "                os.remove(trans_file_path)\n",
    "            else:\n",
    "                print(\"The trans_file_path does not exist\")\n",
    "        print('clean done!')\n",
    "        \n",
    "    def fact_data_extract(self):\n",
    "        datas = []\n",
    "        data_docs, data_trans = self.get_docs_and_trans()\n",
    "        key_ignore = (\"requestId\", \"caseId\", \"caseNumber\", \"created_date\", \"last_modified\", \"documentId\", 'attachmentId', \n",
    "            'system_processing', 'system_processing123', 'hos_image_type', 'remarkCode', 'remarkDescription')\n",
    "        key_ignore_trans = (\"requestId\", \"caseId\", \"caseNumber\", \"created_date\", \"last_modified\", \"documentId\", 'attachmentId', \n",
    "            'system_processing', 'system_processing123', 'hos_image_type', 'remarkCode', 'remarkDescription', 'Images', 'fileName')\n",
    "#         for data in data_trans:\n",
    "#             records = data['records'][0]\n",
    "#             last_modified_utc_7 = data['last_modified'] + datetime.timedelta(hours = 7)\n",
    "#             list_keys = list(records.keys())\n",
    "#             list_values = list(records.values())\n",
    "#             user_name = None\n",
    "#             step_type = None\n",
    "#             process_type = 'transform'\n",
    "#             module_type = 'transform_data'\n",
    "#             process_key = func.get_process_key(module_type, process_type, step_type)\n",
    "#             for i in range(len(list_keys)):\n",
    "#                 last_modified_date_key_utc_7, last_modified_time_key_utc_7 = func.handle_date_to_date_and_time_id(last_modified_utc_7)\n",
    "#                 field_name_temp = list_keys[i]\n",
    "#                 if field_name_temp in key_ignore_trans or field_name_temp.startswith('classify'):\n",
    "#                     continue\n",
    "#                 elif (field_name_temp.startswith('cl') or field_name_temp.startswith('ocr_')) and field_name_temp != 'claimNature':\n",
    "#                     continue\n",
    "#                 field_name = func.lower_first_string(field_name_temp)\n",
    "#                 field_value = list_values[i]\n",
    "#                 _obj = FactDataExtractionModel(\n",
    "#                     project_id = self.project_id,\n",
    "#                     document_id = func.bson_object_to_string(data['doc_id']),\n",
    "#                     doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "#                     last_modified_date_key = last_modified_date_key_utc_7,\n",
    "#                     last_modified_time_key = last_modified_time_key_utc_7,\n",
    "#                     last_modified_timestamp = last_modified_utc_7,\n",
    "#                     user_name = user_name,\n",
    "#                     process_key = process_key,\n",
    "#                     field_name = field_name,\n",
    "#                     field_value = field_value\n",
    "#                 )\n",
    "#                 datas.append(_obj)\n",
    "        for data in data_docs:\n",
    "            if len(data['records']) == 0:\n",
    "                continue\n",
    "            meta_data = data['project_meta_data']\n",
    "            last_modified_utc_7 = data['last_modified'] + datetime.timedelta(hours = 7)\n",
    "            last_modified_date_key_utc_7, last_modified_time_key_utc_7 = func.handle_date_to_date_and_time_id(last_modified_utc_7)\n",
    "            records = data['records'][0]\n",
    "            for key, value in records.items():\n",
    "                if key == 'keyed_data':\n",
    "                    for keyed_data in value:\n",
    "                        if (keyed_data['section'] == 'Auto_Extract' and keyed_data['source'] == 'queue_transform') or \\\n",
    "                            (keyed_data['section'] == 'Verify_Data' and keyed_data['source'] == 'queue_transform'):\n",
    "                            process_type = func.fix_process_type_keyed_data(keyed_data['section'])\n",
    "                            user_name = None\n",
    "                            data_obj = keyed_data['data'][0]\n",
    "                            list_keys = list(data_obj.keys())\n",
    "                            list_values = list(data_obj.values())\n",
    "                            for i in range(len(list_values)):\n",
    "                                field_name_temp = list_keys[i]\n",
    "                                step_type = func.fix_step_type_keyed_data(field_name_temp)\n",
    "                                field_name = func.fix_field_name_keyed_data(field_name_temp)\n",
    "                                if field_name in key_ignore:\n",
    "                                    continue\n",
    "                                field_value = list_values[i]['text']\n",
    "                                process_key = func.get_process_key(module_type, process_type, step_type)                    \n",
    "                                _obj = FactDataExtractionModel(\n",
    "                                    project_id = self.project_id,\n",
    "                                    document_id = func.bson_object_to_string(meta_data['documents'][0]['documentId']),\n",
    "                                    doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "                                    last_modified_date_key = last_modified_date_key_utc_7,\n",
    "                                    last_modified_time_key = last_modified_time_key_utc_7,\n",
    "                                    last_modified_timestamp = last_modified_utc_7,\n",
    "                                    user_name = user_name,\n",
    "                                    process_key = process_key,\n",
    "                                    field_name = field_name,\n",
    "                                    field_value = field_value\n",
    "                                )\n",
    "                                datas.append(_obj)\n",
    "#                 elif key == 'system_data':\n",
    "#                     module_type = 'system_data'\n",
    "#                     system_data = value[0]\n",
    "#                     data_obj = system_data['data'][0]\n",
    "#                     auto_qc_output_data = data_obj['auto_qc_output_data']\n",
    "#                     user_name = None\n",
    "#                     process_type = 'automaticQualityControl'\n",
    "#                     step_type = None  \n",
    "#                     process_key = func.get_process_key(module_type, process_type, step_type)\n",
    "#                     if auto_qc_output_data != []:\n",
    "#                         for item in auto_qc_output_data:\n",
    "#                             field_name_temp = item['field_name']\n",
    "#                             field_name = func.lower_first_string(field_name_temp)\n",
    "#                             if field_name in key_ignore:\n",
    "#                                 continue\n",
    "#                             _obj = FactDataExtractionModel(\n",
    "#                                 project_id = self.project_id,\n",
    "#                                 document_id = func.bson_object_to_string(meta_data['documents'][0]['documentId']),\n",
    "#                                 doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "#                                 last_modified_date_key = last_modified_date_key_utc_7,\n",
    "#                                 last_modified_time_key = last_modified_time_key_utc_7,\n",
    "#                                 last_modified_timestamp = last_modified_utc_7,\n",
    "#                                 user_name = user_name,\n",
    "#                                 process_key = process_key,\n",
    "#                                 field_name = field_name,\n",
    "#                                 field_value = 1\n",
    "#                             )\n",
    "#                             datas.append(_obj)\n",
    "\n",
    "#                 elif key == 'qc_ed_data':\n",
    "#                     module_type = 'qc_ed_data'\n",
    "#                     qc_ed_data = value[0][0]\n",
    "#                     if 'qc_fields_err' not in qc_ed_data.keys():\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         data_obj = qc_ed_data['qc_fields_err']\n",
    "#                         user_name = qc_ed_data['qcer']\n",
    "#                         step_type = None\n",
    "#                         process_type = func.fix_process_type_keyed_data(qc_ed_data['section'])\n",
    "#                         process_key = func.get_process_key(module_type, process_type, step_type)\n",
    "#                         for item in data_obj:\n",
    "#                             field_name_temp = item['field']\n",
    "#                             if field_name_temp in key_ignore:\n",
    "#                                 continue\n",
    "#                             field_name = func.lower_first_string(field_name_temp)\n",
    "#                             field_value = item['value']['text']\n",
    "#                             _obj = FactDataExtractionModel(\n",
    "#                                 project_id = self.project_id,\n",
    "#                                 document_id = func.bson_object_to_string(meta_data['documents'][0]['documentId']),\n",
    "#                                 doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "#                                 last_modified_date_key = last_modified_date_key_utc_7,\n",
    "#                                 last_modified_time_key = last_modified_time_key_utc_7,\n",
    "#                                 last_modified_timestamp = last_modified_utc_7,\n",
    "#                                 user_name = user_name,\n",
    "#                                 process_key = process_key,\n",
    "#                                 field_name = field_name,\n",
    "#                                 field_value = field_value\n",
    "#                             )\n",
    "#                             datas.append(_obj)\n",
    "#                 elif key == 'apr_ed_data':\n",
    "#                     module_type = 'apr_ed_data'\n",
    "#                     apr_ed_data = value[0][0]\n",
    "#                     process_type = func.fix_process_type_keyed_data(apr_ed_data['section'])\n",
    "#                     step_type = None\n",
    "#                     process_key = func.get_process_key(module_type, process_type, step_type)\n",
    "#                     data_obj = apr_ed_data['data']\n",
    "#                     for item in data_obj:\n",
    "#                         field_name_temp = item['field']\n",
    "#                         if field_name_temp in key_ignore:\n",
    "#                             continue\n",
    "#                         field_name = func.lower_first_string(field_name_temp)\n",
    "#                         field_value = item['value']['text']\n",
    "#                         user_name = item['aper']\n",
    "#                         _obj = FactDataExtractionModel(\n",
    "#                             project_id = self.project_id,\n",
    "#                             document_id = func.bson_object_to_string(meta_data['documents'][0]['documentId']),\n",
    "#                             doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "#                             last_modified_date_key = last_modified_date_key_utc_7,\n",
    "#                             last_modified_time_key = last_modified_time_key_utc_7,\n",
    "#                             last_modified_timestamp = last_modified_utc_7,\n",
    "#                             user_name = user_name,\n",
    "#                             process_key = process_key,\n",
    "#                             field_name = field_name,\n",
    "#                             field_value = field_value\n",
    "#                         )\n",
    "#                         datas.append(_obj)\n",
    "#                 elif key == 'final_data':\n",
    "#                     module_type = 'final_data'\n",
    "#                     final_data = value[0]\n",
    "#                     user_name = None\n",
    "#                     data_obj = final_data['data']\n",
    "#                     process_type = 'finalize'\n",
    "#                     for item in data_obj:\n",
    "#                         field_name_temp = list(item.keys())[0]\n",
    "#                         if field_name_temp in key_ignore or field_name_temp.startswith('cl') or field_name_temp.startswith('ocr_'):\n",
    "#                             continue\n",
    "#                         step_type = None\n",
    "#                         field_name = func.fix_field_name_keyed_data(field_name_temp)\n",
    "#                         field_value = list(item.values())[0]['text']\n",
    "#                         process_key = func.get_process_key(module_type, process_type, step_type)\n",
    "#                         _obj = FactDataExtractionModel(\n",
    "#                             project_id = self.project_id,\n",
    "#                             document_id = func.bson_object_to_string(meta_data['documents'][0]['documentId']),\n",
    "#                             doc_set_id =  func.bson_object_to_string(data['doc_set_id']),\n",
    "#                             last_modified_date_key = last_modified_date_key_utc_7,\n",
    "#                             last_modified_time_key = last_modified_time_key_utc_7,\n",
    "#                             last_modified_timestamp = last_modified_utc_7,\n",
    "#                             user_name = user_name,\n",
    "#                             process_key = process_key,\n",
    "#                             field_name = field_name,\n",
    "#                             field_value = field_value\n",
    "#                         )\n",
    "#                         datas.append(_obj)\n",
    "#         if datas != []:\n",
    "#             print(datas[0].__dict__)\n",
    "        for data in datas:\n",
    "            print(data.field_name, data.field_value)\n",
    "        self.db.create([item.__dict__ for item in datas], self.schema, self.fact_data_extraction)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'module_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-aa03fb5e40da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# executor.backup_performance()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# executor.fact_document()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfact_data_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m# executor.fact_performance()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# executor.report()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-05ce26bb0ef0>\u001b[0m in \u001b[0;36mfact_data_extract\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                                 \u001b[0mfield_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m                                 \u001b[0mprocess_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_process_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m                                 _obj = FactDataExtractionModel(\n\u001b[0;32m    269\u001b[0m                                     \u001b[0mproject_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'module_type' is not defined"
     ]
    }
   ],
   "source": [
    "db_connect = DatabaseConnect(uri = config.DWH_SQLALCHEMY_URI)\n",
    "executor = EclaimsExecutor(\n",
    "    environment=config.ENVIRONMENT,\n",
    "    uri=config.ELROND_URI,\n",
    "    database_name=config.ELROND_DATABASE,\n",
    "    docs_collection_name= config.ECLAIMS_DOCS_COLLECTION, \n",
    "    trans_collection_name= config.ECLAIMS_TRANS_COLLECTION,\n",
    "    performance_collection_name = config.ECLAIMS_PERFORMANCE_COLLECTION,\n",
    "    db = db_connect\n",
    ")\n",
    "# executor.clean()\n",
    "# executor.backup_docs()\n",
    "# executor.backup_trans()\n",
    "# executor.backup_performance()\n",
    "# executor.fact_document()\n",
    "executor.fact_data_extract()\n",
    "# executor.fact_performance()\n",
    "# executor.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_params = {\n",
    "    'dag_id': \"dwh_eclaims_project_daily_tmp\",\n",
    "    'start_date': datetime.datetime(2021, 1, 6, tzinfo=config.LOCAL_TIME_ZONE),\n",
    "    'schedule_interval': '20 5 * * *'\n",
    "}\n",
    "\n",
    "dag = DAG(**dag_params)\n",
    "\n",
    "clean = PythonOperator(task_id='clean', python_callable=executor.clean, dag=dag)\n",
    "check_connect = PythonOperator(task_id='check_connect', python_callable=executor.check_connect, dag=dag)\n",
    "backup_docs_json = PythonOperator(task_id='backup_docs_json', python_callable=executor.backup_docs_json, dag=dag, trigger_rule=TriggerRule.ALL_SUCCESS)\n",
    "backup_trans_json = PythonOperator(task_id='backup_trans_json', python_callable=executor.backup_trans_json, dag=dag, trigger_rule=TriggerRule.ALL_SUCCESS)\n",
    "backup_performance = PythonOperator(task_id='backup_performance', python_callable=executor.backup_performance, dag=dag, trigger_rule=TriggerRule.ALL_SUCCESS)\n",
    "\n",
    "\n",
    "fact_performance = PythonOperator(task_id='fact_performance', python_callable=executor.fact_performance, dag=dag, trigger_rule=TriggerRule.ALL_SUCCESS)\n",
    "fact_document = PythonOperator(task_id='fact_document', python_callable=executor.fact_document, dag=dag, trigger_rule=TriggerRule.ALL_SUCCESS)\n",
    "\n",
    "\n",
    "report = PythonOperator(task_id='report', python_callable=executor.report, dag=dag, trigger_rule=TriggerRule.ALL_DONE)\n",
    "\n",
    "clean >> check_connect >> [backup_trans_json, backup_docs_json, backup_performance]\n",
    "\n",
    "fact_performance.set_upstream(backup_performance)\n",
    "fact_document.set_upstream([backup_trans_json, backup_docs_json])\n",
    "\n",
    "[fact_performance, fact_document] >> report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = pickle.load(open('./backup/trans/' + '5db5c87345052400142992e9' + '.pickle', 'rb'))\n",
    "docs = pickle.load(open('./backup/docs/' + '5db5c87345052400142992e9' + '.pickle', 'rb'))\n",
    "performance = pickle.load(open('./backup/performance/' + '5db5c87345052400142992e9' + '.pickle', 'rb'))\n",
    "# keyed_data\n",
    "# qc\n",
    "\n",
    "# pprint(performance)\n",
    "x = []\n",
    "for data in docs:\n",
    "    pprint(data)\n",
    "    break\n",
    "    ocr_results = data['records'][0]['system_data'][0]['ocr_data'][0]['ocr_results']\n",
    "    for ocr_result in ocr_results:\n",
    "        field_name = ocr_result['field_name']\n",
    "        if field_name not in x: \n",
    "            x.append(field_name)\n",
    "print(x)\n",
    "['address', 'birthday', 'expiry', 'home_town', 'id', 'issue_at', 'issue_date', 'name', 'sex']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
